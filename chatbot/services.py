import logging
import uuid
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Any
from collections import defaultdict
import json
import re

import google.generativeai as genai
from qdrant_client import QdrantClient
from qdrant_client.http import models as rest
from bson import ObjectId
from pymongo import DESCENDING, ASCENDING

from config import settings
from database import get_mongo_db
from models import ChatRequest, ChatResponse, ChatHistory, SourcedAnswer, ChatContext

logger = logging.getLogger(__name__)

# --- SYSTEM PROMPT ROUTER ---
SYSTEM_PROMPT_ROUTER = """
B·∫°n l√† AI Query Router. Nhi·ªám v·ª•: Ph√¢n t√≠ch ng·ªØ c·∫£nh v√† c√¢u h·ªèi ƒë·ªÉ ƒë·ªãnh tuy·∫øn.

--- INPUT DATA ---
1. Context Page: "home_page" | "list_page" | "detail_page"
2. Query: C√¢u h·ªèi user.
3. Chat History: L·ªãch s·ª≠.

--- PH√ÇN T√çCH ---
1. X√ÅC ƒê·ªäNH DEPENDENCY (S·ª± ph·ª• thu·ªôc):
    - "main": C√¢u h·ªèi ƒê·ªòC L·∫¨P, ƒë·∫ßy ƒë·ªß ch·ªß ng·ªØ/v·ªã ng·ªØ ho·∫∑c m·ªü ra ch·ªß ƒë·ªÅ m·ªõi.
    - "sub": C√¢u h·ªèi PH·ª§ THU·ªòC (Follow-up). D·∫•u hi·ªáu: 
        + ƒê·∫°i t·ª´ thay th·∫ø ("n√≥", "√¥ng ·∫•y", "b√†i n√†y", "danh s√°ch ƒë√≥", ...).
        + C√¢u h·ªèi ng·∫Øn/c·ª•t ("th·∫ø c√≤n t√°c gi·∫£?", "c√≤n ng√†y mai?", "t·∫°i sao?", ...).
        + B·∫Øt ƒë·∫ßu b·∫±ng t·ª´ n·ªëi ("v·∫≠y th√¨", "n·∫øu th·∫ø", ...).

2. INTENT:
    - "contextual_summary": T√≥m t·∫Øt, t·ªïng h·ª£p th√¥ng tin t·ª´ Context hi·ªán t·∫°i (List ho·∫∑c Detail).
    - "specific_detail": H·ªèi chi ti·∫øt v·ªÅ 1 ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ.
    - "general_search": T√¨m ki·∫øm m·ªü r·ªông, ki·∫øn th·ª©c chung.

3. TR√çCH XU·∫§T FILTERS & QUANTITY:
    - website: "vneconomy.vn" | "vnexpress.net"
    - days_ago: int (VD: "3 ng√†y qua" -> 3)
    - topic: string (Ch·ªß ƒë·ªÅ b√†i b√°o. C·ªë g·∫Øng tr√≠ch xu·∫•t t√™n chuy√™n m·ª•c ch√≠nh x√°c n·∫øu c√≥ th·ªÉ).
    - sentiment: "positive" | "negative"
    - quantity: int (S·ªë l∆∞·ª£ng b√†i b√°o user mu·ªën x·ª≠ l√Ω. VD: "5 b√†i ƒë·∫ßu", "top 3" -> 5, 3. M·∫∑c ƒë·ªãnh null).

--- LOGIC MATRIX ---
| Page | Query keywords | -> Intent |
| :--- | :--- | :--- |
| **list_page** | T·ª´ kh√≥a s·ªë nhi·ªÅu ("c√°c b√†i", "danh s√°ch", "nh·ªØng tin n√†y") HO·∫∂C t·ª´ kh√≥a t√≥m t·∫Øt ("t·ªïng h·ª£p", "ƒëi·ªÉm tin") | -> **contextual_summary** |
| **detail_page** | H·ªèi t√≥m t·∫Øt, n·ªôi dung ch√≠nh, ƒë·∫°i √Ω | -> **contextual_summary** |
| **detail_page** | H·ªèi ai, c√°i g√¨, ·ªü ƒë√¢u, khi n√†o (c·ªßa b√†i b√°o n√†y) | -> **specific_detail** |
| **home_page** | B·∫•t k·ª≥ c√¢u h·ªèi n√†o | -> **general_search** |

OUTPUT JSON:
{
    "intent": "string",
    "dependency": "string",
    "filters": {
        "website": "string | null",
        "days_ago": "integer | null",
        "topic": "string | null",
        "sentiment": "string | null",
        "quantity": "integer | null"
    }
}
"""

SYSTEM_PROMPT_CHAT = (
    "B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh. Tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin cung c·∫•p.\n"
    "L∆ØU √ù QUAN TR·ªåNG:\n"
    "- N·∫øu c√¢u h·ªèi l√† c√¢u ph·ª• (Sub-question) ho·∫∑c tham chi·∫øu s·ªë th·ª© t·ª± (v√≠ d·ª•: 'b√†i 1', 'tin ƒë·∫ßu ti√™n', 'ph·∫ßn 1'), h√£y CƒÇN C·ª® V√ÄO L·ªäCH S·ª¨ CHAT (c√¢u tr·∫£ l·ªùi tr∆∞·ªõc c·ªßa Bot) ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c b√†i b√°o ƒëang ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn.\n"
    "- N·∫øu c√¢u h·ªèi l√† c√¢u ch√≠nh (main) tr·∫£ l·ªùi m√† kh√¥ng c·∫ßn d·ª±a v√†o l·ªãch s·ª≠ chat.\n"
    "- Lu√¥n tr√≠ch d·∫´n ngu·ªìn (Source) cho m·ªçi th√¥ng tin ƒë∆∞a ra, m·ªói b√†i b√°o ch·ªâ tr√≠ch d·∫´n ngu·ªìn 1 l·∫ßn duy nh·∫•t."
)

class ChatService:
    def __init__(self):
        try:
            genai.configure(api_key=settings.google_api_key)
            self.llm = genai.GenerativeModel('gemini-2.5-flash', system_instruction=SYSTEM_PROMPT_CHAT)
            self.router_llm = genai.GenerativeModel('gemini-2.5-flash', generation_config={"response_mime_type": "application/json"})
            self.embedding_model = 'models/text-embedding-004'
            self.vector_size = 384
            
            self.db = get_mongo_db()
            self.chat_histories_collection = self.db['chat_histories']
            self.articles_collection = self.db['articles'] 
            
            self.qdrant_client = QdrantClient(url=settings.qdrant_url, api_key=settings.qdrant_api_key)
            self.qdrant_collection_name = settings.qdrant_collection_name
            logger.info(f"ChatService V13.8 Ready (Updated: General Search uses 'chunk' type).")
        except Exception as e:
            logger.error(f"Init Error: {e}")
            raise

    async def _get_chat_history(self, user_id: str, conversation_id: str) -> List[ChatHistory]:
        cursor = self.chat_histories_collection.find({
            "user_id": user_id, "conversation_id": conversation_id
        }).sort("created_at", -1).limit(5)
        history = await cursor.to_list(length=5)
        return [ChatHistory(**h) for h in history]

    async def _save_chat_history(self, user_id: str, conversation_id: str, query: str, answer: str, intent: str, dependency: str):
        await self.chat_histories_collection.insert_one({
            "user_id": user_id, "conversation_id": conversation_id,
            "query": query, "answer": answer, 
            "intent": intent, "dependency": dependency,
            "created_at": datetime.utcnow()
        })

    async def _analyze_query(self, query: str, history: List[ChatHistory], context: ChatContext) -> Dict[str, Any]:
        try:
            chronological_history = list(reversed(history))
            history_txt = "\n".join([f"User: {h.query}\nBot: {h.answer}" for h in chronological_history])
            
            prompt = (
                f"{SYSTEM_PROMPT_ROUTER}\n\n"
                f"--- RUNTIME DATA ---\n"
                f"Context Page: {context.current_page}\n"
                f"Chat History:\n{history_txt}\n"
                f"Current Query: {query}\n"
            )
            response = await self.router_llm.generate_content_async(prompt)
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Router Error: {e}")
            return {"dependency": "main", "intent": "general_search", "filters": {}}

    async def _get_top_article_ids_from_mongo(self, search_id: str, sort_by: str, sort_order: str, limit: int) -> List[str]:
        """
        Truy v·∫•n MongoDB ƒë·ªÉ l·∫•y danh s√°ch Article ID ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp ch√≠nh x√°c.
        """
        if not search_id:
            return []
        
        # Mapping sort key
        sort_field = "publish_date"
        if sort_by == "sentiment":
            sort_field = "sentiment"
        elif sort_by == "publish_date":
            sort_field = "publish_date"
            
        direction = DESCENDING if sort_order == "desc" else ASCENDING
        
        logger.info(f"üîç Mongo Sort: search_id={search_id} | field={sort_field} | dir={direction} | limit={limit}")
        
        cursor = self.articles_collection.find(
            {"search_id": search_id},
            {"article_id": 1}
        ).sort(sort_field, direction).limit(limit)
        
        docs = await cursor.to_list(length=limit)
        return [doc["article_id"] for doc in docs if "article_id" in doc]

    def _build_qdrant_filters(self, base_filters: dict, extracted_filters: dict) -> Optional[rest.Filter]:
        conditions = []
        
        # X·ª≠ l√Ω Base Filters (t·ª´ Context)
        for key, value in base_filters.items():
            if value:
                # T·∫•t c·∫£ c√°c key n√†y (article_id, search_id, type) gi·ªù ƒë·ªÅu n·∫±m ·ªü ROOT payload
                if key == "article_id":
                    if isinstance(value, list):
                        conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchAny(any=value)))
                    else:
                        conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchValue(value=value)))
                elif key == "search_id":
                    conditions.append(rest.FieldCondition(key="search_id", match=rest.MatchValue(value=value)))
                else:
                    # C√°c tr∆∞·ªùng kh√°c nh∆∞ 'type'
                    conditions.append(rest.FieldCondition(key=key, match=rest.MatchValue(value=value)))

        ai_filters = extracted_filters.get("filters", {})
        
        # [UPDATE] Website Filter: D√πng key="website" (Root) thay v√¨ metadata.website
        if ai_filters.get("website"):
            conditions.append(rest.FieldCondition(key="website", match=rest.MatchValue(value=ai_filters['website'])))
        
        # [SMART TOPIC FILTER] (Root)
        if ai_filters.get("topic"):
            raw_topic = ai_filters['topic'].strip()
            topic_variations = list(set([
                raw_topic,                  
                raw_topic.lower(),          
                raw_topic.capitalize(),     
                raw_topic.title(),          
                raw_topic.upper()           
            ]))
            logger.info(f"Topic filtering variations: {topic_variations}")
            conditions.append(rest.FieldCondition(key="topic", match=rest.MatchAny(any=topic_variations)))
        
        # [SENTIMENT FILTER] (Root)
        if ai_filters.get("sentiment"):
            val = ai_filters['sentiment']
            if val == "positive": conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(gte=0.25)))
            elif val == "negative": conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(lte=-0.25)))
        
        # [DATE FILTER] (Root)
        if ai_filters.get("days_ago") and isinstance(ai_filters["days_ago"], int):
            cutoff_date = datetime.utcnow() - timedelta(days=ai_filters["days_ago"])
            conditions.append(rest.FieldCondition(key="publish_date", range=rest.DatetimeRange(gte=cutoff_date.isoformat())))

        return rest.Filter(must=conditions) if conditions else None

    async def _search_qdrant(self, query: str, qdrant_filter: Optional[rest.Filter], limit: int = 5) -> List[rest.ScoredPoint]:
        try:
            logger.info(f"üîç Qdrant Search | Limit: {limit} | Filter: {qdrant_filter}")
            embedding_result = genai.embed_content(
                model=self.embedding_model, content=query, task_type="retrieval_query", output_dimensionality=self.vector_size
            )
            
            results = self.qdrant_client.search(
                collection_name=self.qdrant_collection_name,
                query_vector=embedding_result['embedding'],
                query_filter=qdrant_filter,
                limit=limit
            )
            return results
        except Exception as e:
            logger.error(f"‚ùå Qdrant Search Error: {e}")
            return []

    async def _resolve_article_id(self, input_id: str) -> str:
        if not input_id or len(input_id) != 24: return input_id
        try:
            doc = await self.articles_collection.find_one({"_id": ObjectId(input_id)}, {"article_id": 1})
            return doc["article_id"] if doc else input_id
        except: return input_id

    async def handle_chat(self, request: ChatRequest) -> ChatResponse:
        conversation_id = request.conversation_id or str(uuid.uuid4())
        
        if request.context.current_page == "detail_page" and request.context.article_id:
            request.context.article_id = await self._resolve_article_id(request.context.article_id)

        history = await self._get_chat_history(request.user_id, conversation_id)
        
        analysis = await self._analyze_query(request.query, history, request.context)
        intent = analysis.get("intent", "general_search")
        dependency = analysis.get("dependency", "main")
        extracted_filters = analysis.get("filters", {})
        
        requested_quantity = extracted_filters.get("quantity")
        limit = requested_quantity if requested_quantity else 5
        
        logger.info(f"Analysis -> Intent: {intent} | Quantity: {requested_quantity}")

        search_query = request.query
        context_query_append = ""
        if dependency == "sub":
            last_main_query = next((h.query for h in history if getattr(h, 'dependency', 'main') == 'main'), None)
            if last_main_query:
                search_query = f"{last_main_query} {search_query}"
                context_query_append = f"(Ng·ªØ c·∫£nh c≈©: '{last_main_query}')"

        base_filters = {}
        strategy = "Global Search"
        should_fallback_to_global = False

        is_list_sort_context = (
            request.context.current_page == "list_page" and 
            request.context.search_id and 
            request.context.sort_by and 
            request.context.sort_by != "relevance"
        )
        
        # Ki·ªÉm tra c√≥ b·ªô l·ªçc n·ªôi dung c·ª• th·ªÉ kh√¥ng
        has_content_filters = any(
            extracted_filters.get(k) is not None
            for k in ["topic", "website", "sentiment", "days_ago"]
        )

        # --- LOGIC CHI·∫æN L∆Ø·ª¢C T√åM KI·∫æM ---
        
        # 1. Chi ti·∫øt b√†i vi·∫øt
        if request.context.current_page == "detail_page" and request.context.article_id:
             base_filters = {"article_id": request.context.article_id}
             strategy = "Single Page Context"

        # 2. Trang danh s√°ch (List Page)
        elif request.context.current_page == "list_page" and request.context.search_id:
            if has_content_filters:
                base_filters = {"search_id": request.context.search_id}
                strategy = "Scoped Search (With Filters)"
                should_fallback_to_global = True
            elif is_list_sort_context:
                if intent == "contextual_summary" or (dependency == "sub" and intent == "specific_detail"):
                    top_ids = await self._get_top_article_ids_from_mongo(
                        request.context.search_id,
                        request.context.sort_by,
                        request.context.sort_order or "desc",
                        limit
                    )
                    if top_ids:
                        base_filters = {"article_id": top_ids}
                        strategy = f"List Sort ({request.context.sort_by}) [Sub/Summary]"
                        limit = len(top_ids) 
                    else:
                        base_filters = {"search_id": request.context.search_id}
                        strategy = "Session Context (Fallback)"
                else:
                    base_filters = {"search_id": request.context.search_id}
                    strategy = "Session Context (Filtered)"
            
            # --- UPDATE: T√°ch Logic Summary v√† Search ---
            elif intent == "contextual_summary":
                # N·∫øu mu·ªën t√≥m t·∫Øt, ch·ªâ t√¨m trong list hi·ªán t·∫°i, KH√îNG fallback ra ngo√†i
                base_filters = {"search_id": request.context.search_id}
                strategy = "Session Context (Summary)"
            
            elif intent == "general_search":
                # N·∫øu t√¨m ki·∫øm th√¥ng tin, ∆∞u ti√™n t√¨m trong list, nh∆∞ng cho ph√©p fallback ra to√†n DB
                base_filters = {"search_id": request.context.search_id}
                strategy = "Session Context (Search)"
                should_fallback_to_global = True 
        
        # [UPDATE]: Logic x√°c ƒë·ªãnh Type d·ª±a tr√™n Intent
        if intent == "contextual_summary":
            base_filters["type"] = "ai_summary"
        elif intent == "general_search":
            base_filters["type"] = "chunk" # general_search -> t√¨m trong chunk
        elif "type" not in base_filters:
            base_filters["type"] = "ai_summary" # M·∫∑c ƒë·ªãnh c≈©

        # --- TH·ª∞C HI·ªÜN T√åM KI·∫æM ---

        # 1. INITIAL SEARCH
        final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
        results = await self._search_qdrant(search_query, final_filter, limit=limit)

        # 2. FALLBACK 0: Scoped -> Global
        if not results and should_fallback_to_global:
            logger.info("‚ö†Ô∏è Scoped Search empty. Fallback to Global Search...")
            if "search_id" in base_filters: 
                del base_filters["search_id"]
            
            final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
            results = await self._search_qdrant(search_query, final_filter, limit=limit)
            
            if results:
                strategy = "Global Search (Fallback from Scoped)"

        # 3. FALLBACK A: B·ªè type=ai_summary
        if not results and base_filters.get("type") == "ai_summary":
            logger.info("‚ö†Ô∏è No pre-computed summaries found. Fallback to full text search...")
            if "type" in base_filters: 
                del base_filters["type"]
            
            final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
            results = await self._search_qdrant(search_query, final_filter, limit=limit)

        # 4. FALLBACK B: B·ªè Topic/Content Filters (Ch·ªâ gi·ªØ Keyword)
        if not results and has_content_filters:
            logger.info("‚ö†Ô∏è Still no results. Relaxing strict content filters...")
            relaxed_filters = extracted_filters.copy()
            for key in ["topic", "website", "days_ago"]:
                if key in relaxed_filters:
                    del relaxed_filters[key]
            
            final_filter = self._build_qdrant_filters(base_filters, {"filters": relaxed_filters})
            results = await self._search_qdrant(search_query, final_filter, limit=limit)
            if results:
                strategy += " (Relaxed Filters)"

        context_parts = []
        sources = []
        seen = set()

        if not results:
            if intent == "contextual_summary":
                final_answer = "Hi·ªán kh√¥ng t√¨m th·∫•y b√†i b√°o n√†o ph√π h·ª£p v·ªõi y√™u c·∫ßu ƒë·ªÉ t√≥m t·∫Øt."
            else:
                final_answer = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong danh s√°ch n√†y."
        else:
            for pt in results:
                payload = pt.payload or {}
                content = payload.get("summary_text") if payload.get("type") == "ai_summary" else payload.get("text", "")
                content = "\n- ".join(content) if isinstance(content, list) else str(content)
                
                title = payload.get("title", "No Title")
                # L·∫•y ID t·ª´ root ho·∫∑c metadata
                aid = payload.get("article_id") or payload.get("metadata", {}).get("article_id", "unknown")
                
                # --- NEW: Extract Metadata for Prompt ---
                publish_date = payload.get("publish_date", "N/A")
                
                # ∆Øu ti√™n l·∫•y 'ai_sentiment_score', n·∫øu kh√¥ng c√≥ th√¨ l·∫•y 'sentiment'
                sentiment_score = payload.get("ai_sentiment_score", payload.get("sentiment", "N/A"))
                
                # ∆Øu ti√™n l·∫•y 'site_categories', n·∫øu kh√¥ng c√≥ th√¨ l·∫•y 'topic'
                site_categories = payload.get("site_categories", payload.get("topic", "N/A"))
                
                context_parts.append(
                    f"--- B√†i: {title} ---\n"
                    f"Ng√†y ƒëƒÉng: {publish_date}\n"
                    f"Ch·ªâ s·ªë c·∫£m x√∫c: {sentiment_score}\n"
                    f"Ch·ªß ƒë·ªÅ/Categories: {site_categories}\n"
                    f"N·ªôi dung:\n{content}"
                )
                
                if title not in seen:
                    sources.append(SourcedAnswer(article_id=str(aid), title=title))
                    seen.add(title)

            chat_history_str = chr(10).join([
                f"- User: {h.query}\n  Bot: {h.answer}" 
                for h in reversed(history[:2])
            ])

            prompt = (
                f"C√¢u h·ªèi ng∆∞·ªùi d√πng: {request.query} {context_query_append}\n"
                f"L·ªãch s·ª≠ h·ªôi tho·∫°i (ƒë·ªÉ tham kh·∫£o ng·ªØ c·∫£nh):\n"
                f"{chat_history_str}\n\n"
                f"D·ªØ li·ªáu t√¨m ƒë∆∞·ª£c ({strategy}):\n{chr(10).join(context_parts)}\n\n"
                f"Y√äU C·∫¶U: Tr·∫£ l·ªùi c√¢u h·ªèi tr√™n. N·∫øu d·ªØ li·ªáu l√† c√°c b√†i b√°o r·ªùi r·∫°c, h√£y t·ªïng h·ª£p ch√∫ng th√†nh m·ªôt b·∫£n t√≥m t·∫Øt m·∫°ch l·∫°c."
            )
            resp = await self.llm.generate_content_async(prompt)
            final_answer = resp.text

        await self._save_chat_history(request.user_id, conversation_id, request.query, final_answer, intent, dependency)
        
        return ChatResponse(
            answer=final_answer, conversation_id=conversation_id, sources=sources,
            intent_detected=intent, dependency_label=dependency, strategy_used=strategy
        )




# import logging
# import uuid
# import asyncio
# from datetime import datetime, timedelta
# from typing import List, Dict, Optional, Tuple, Any
# from collections import defaultdict
# import json
# import re

# import google.generativeai as genai
# from qdrant_client import QdrantClient
# from qdrant_client.http import models as rest
# from bson import ObjectId
# from pymongo import DESCENDING, ASCENDING

# from config import settings
# from database import get_mongo_db
# from models import ChatRequest, ChatResponse, ChatHistory, SourcedAnswer, ChatContext

# logger = logging.getLogger(__name__)

# # --- SYSTEM PROMPT ROUTER ---
# SYSTEM_PROMPT_ROUTER = """
# B·∫°n l√† AI Query Router. Nhi·ªám v·ª•: Ph√¢n t√≠ch ng·ªØ c·∫£nh v√† c√¢u h·ªèi ƒë·ªÉ ƒë·ªãnh tuy·∫øn.

# --- INPUT DATA ---
# 1. Context Page: "home_page" | "list_page" | "detail_page"
# 2. Query: C√¢u h·ªèi user.
# 3. Chat History: L·ªãch s·ª≠.

# --- PH√ÇN T√çCH ---
# 1. X√ÅC ƒê·ªäNH DEPENDENCY (S·ª± ph·ª• thu·ªôc):
#     - "main": C√¢u h·ªèi ƒê·ªòC L·∫¨P, ƒë·∫ßy ƒë·ªß ch·ªß ng·ªØ/v·ªã ng·ªØ ho·∫∑c m·ªü ra ch·ªß ƒë·ªÅ m·ªõi.
#     - "sub": C√¢u h·ªèi PH·ª§ THU·ªòC (Follow-up). D·∫•u hi·ªáu: 
#         + ƒê·∫°i t·ª´ thay th·∫ø ("n√≥", "√¥ng ·∫•y", "b√†i n√†y", "danh s√°ch ƒë√≥", ...).
#         + C√¢u h·ªèi ng·∫Øn/c·ª•t ("th·∫ø c√≤n t√°c gi·∫£?", "c√≤n ng√†y mai?", "t·∫°i sao?", ...).
#         + B·∫Øt ƒë·∫ßu b·∫±ng t·ª´ n·ªëi ("v·∫≠y th√¨", "n·∫øu th·∫ø", ...).

# 2. INTENT:
#     - "contextual_summary": T√≥m t·∫Øt, t·ªïng h·ª£p th√¥ng tin t·ª´ Context hi·ªán t·∫°i (List ho·∫∑c Detail).
#     - "specific_detail": H·ªèi chi ti·∫øt v·ªÅ 1 ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ.
#     - "general_search": T√¨m ki·∫øm m·ªü r·ªông, ki·∫øn th·ª©c chung.

# 3. TR√çCH XU·∫§T FILTERS & QUANTITY:
#     - website: "vneconomy.vn" | "vnexpress.net"
#     - days_ago: int (VD: "3 ng√†y qua" -> 3)
#     - topic: string (Ch·ªß ƒë·ªÅ b√†i b√°o. C·ªë g·∫Øng tr√≠ch xu·∫•t t√™n chuy√™n m·ª•c ch√≠nh x√°c n·∫øu c√≥ th·ªÉ).
#     - sentiment: "positive" | "negative"
#     - quantity: int (S·ªë l∆∞·ª£ng b√†i b√°o user mu·ªën x·ª≠ l√Ω. VD: "5 b√†i ƒë·∫ßu", "top 3" -> 5, 3. M·∫∑c ƒë·ªãnh null).

# --- LOGIC MATRIX ---
# | Page | Query keywords | -> Intent |
# | :--- | :--- | :--- |
# | **list_page** | T·ª´ kh√≥a s·ªë nhi·ªÅu ("c√°c b√†i", "danh s√°ch", "nh·ªØng tin n√†y") HO·∫∂C t·ª´ kh√≥a t√≥m t·∫Øt ("t·ªïng h·ª£p", "ƒëi·ªÉm tin") | -> **contextual_summary** |
# | **detail_page** | H·ªèi t√≥m t·∫Øt, n·ªôi dung ch√≠nh, ƒë·∫°i √Ω | -> **contextual_summary** |
# | **detail_page** | H·ªèi ai, c√°i g√¨, ·ªü ƒë√¢u, khi n√†o (c·ªßa b√†i b√°o n√†y) | -> **specific_detail** |
# | **home_page** | B·∫•t k·ª≥ c√¢u h·ªèi n√†o | -> **general_search** |

# OUTPUT JSON:
# {
#     "intent": "string",
#     "dependency": "string",
#     "filters": {
#         "website": "string | null",
#         "days_ago": "integer | null",
#         "topic": "string | null",
#         "sentiment": "string | null",
#         "quantity": "integer | null"
#     }
# }
# """

# SYSTEM_PROMPT_CHAT = (
#     "B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh. Tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin cung c·∫•p.\n"
#     "L∆ØU √ù QUAN TR·ªåNG:\n"
#     "- N·∫øu c√¢u h·ªèi l√† c√¢u ph·ª• (Sub-question) ho·∫∑c tham chi·∫øu s·ªë th·ª© t·ª± (v√≠ d·ª•: 'b√†i 1', 'tin ƒë·∫ßu ti√™n', 'ph·∫ßn 1'), h√£y CƒÇN C·ª® V√ÄO L·ªäCH S·ª¨ CHAT (c√¢u tr·∫£ l·ªùi tr∆∞·ªõc c·ªßa Bot) ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c b√†i b√°o ƒëang ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn.\n"
#     "- N·∫øu c√¢u h·ªèi l√† c√¢u ch√≠nh (main) tr·∫£ l·ªùi m√† kh√¥ng c·∫ßn d·ª±a v√†o l·ªãch s·ª≠ chat.\n"
#     "- Lu√¥n tr√≠ch d·∫´n ngu·ªìn (Source) cho m·ªçi th√¥ng tin ƒë∆∞a ra, m·ªói b√†i b√°o ch·ªâ tr√≠ch d·∫´n ngu·ªìn 1 l·∫ßn duy nh·∫•t."
# )

# class ChatService:
#     def __init__(self):
#         try:
#             genai.configure(api_key=settings.google_api_key)
#             self.llm = genai.GenerativeModel('gemini-2.5-flash', system_instruction=SYSTEM_PROMPT_CHAT)
#             self.router_llm = genai.GenerativeModel('gemini-2.5-flash', generation_config={"response_mime_type": "application/json"})
#             self.embedding_model = 'models/text-embedding-004'
#             self.vector_size = 384
            
#             self.db = get_mongo_db()
#             self.chat_histories_collection = self.db['chat_histories']
#             self.articles_collection = self.db['articles'] 
            
#             self.qdrant_client = QdrantClient(url=settings.qdrant_url, api_key=settings.qdrant_api_key)
#             self.qdrant_collection_name = settings.qdrant_collection_name
#             logger.info(f"ChatService V13.7 Ready (Updated: Logic List Page Fallback to Global).")
#         except Exception as e:
#             logger.error(f"Init Error: {e}")
#             raise

#     async def _get_chat_history(self, user_id: str, conversation_id: str) -> List[ChatHistory]:
#         cursor = self.chat_histories_collection.find({
#             "user_id": user_id, "conversation_id": conversation_id
#         }).sort("created_at", -1).limit(5)
#         history = await cursor.to_list(length=5)
#         return [ChatHistory(**h) for h in history]

#     async def _save_chat_history(self, user_id: str, conversation_id: str, query: str, answer: str, intent: str, dependency: str):
#         await self.chat_histories_collection.insert_one({
#             "user_id": user_id, "conversation_id": conversation_id,
#             "query": query, "answer": answer, 
#             "intent": intent, "dependency": dependency,
#             "created_at": datetime.utcnow()
#         })

#     async def _analyze_query(self, query: str, history: List[ChatHistory], context: ChatContext) -> Dict[str, Any]:
#         try:
#             chronological_history = list(reversed(history))
#             history_txt = "\n".join([f"User: {h.query}\nBot: {h.answer}" for h in chronological_history])
            
#             prompt = (
#                 f"{SYSTEM_PROMPT_ROUTER}\n\n"
#                 f"--- RUNTIME DATA ---\n"
#                 f"Context Page: {context.current_page}\n"
#                 f"Chat History:\n{history_txt}\n"
#                 f"Current Query: {query}\n"
#             )
#             response = await self.router_llm.generate_content_async(prompt)
#             return json.loads(response.text)
#         except Exception as e:
#             logger.error(f"Router Error: {e}")
#             return {"dependency": "main", "intent": "general_search", "filters": {}}

#     async def _get_top_article_ids_from_mongo(self, search_id: str, sort_by: str, sort_order: str, limit: int) -> List[str]:
#         """
#         Truy v·∫•n MongoDB ƒë·ªÉ l·∫•y danh s√°ch Article ID ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp ch√≠nh x√°c.
#         """
#         if not search_id:
#             return []
        
#         # Mapping sort key
#         sort_field = "publish_date"
#         if sort_by == "sentiment":
#             sort_field = "sentiment"
#         elif sort_by == "publish_date":
#             sort_field = "publish_date"
            
#         direction = DESCENDING if sort_order == "desc" else ASCENDING
        
#         logger.info(f"üîç Mongo Sort: search_id={search_id} | field={sort_field} | dir={direction} | limit={limit}")
        
#         cursor = self.articles_collection.find(
#             {"search_id": search_id},
#             {"article_id": 1}
#         ).sort(sort_field, direction).limit(limit)
        
#         docs = await cursor.to_list(length=limit)
#         return [doc["article_id"] for doc in docs if "article_id" in doc]

#     def _build_qdrant_filters(self, base_filters: dict, extracted_filters: dict) -> Optional[rest.Filter]:
#         conditions = []
        
#         # X·ª≠ l√Ω Base Filters (t·ª´ Context)
#         for key, value in base_filters.items():
#             if value:
#                 # T·∫•t c·∫£ c√°c key n√†y (article_id, search_id, type) gi·ªù ƒë·ªÅu n·∫±m ·ªü ROOT payload
#                 if key == "article_id":
#                     if isinstance(value, list):
#                         conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchAny(any=value)))
#                     else:
#                         conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchValue(value=value)))
#                 elif key == "search_id":
#                     conditions.append(rest.FieldCondition(key="search_id", match=rest.MatchValue(value=value)))
#                 else:
#                     # C√°c tr∆∞·ªùng kh√°c nh∆∞ 'type'
#                     conditions.append(rest.FieldCondition(key=key, match=rest.MatchValue(value=value)))

#         ai_filters = extracted_filters.get("filters", {})
        
#         # [UPDATE] Website Filter: D√πng key="website" (Root) thay v√¨ metadata.website
#         if ai_filters.get("website"):
#             conditions.append(rest.FieldCondition(key="website", match=rest.MatchValue(value=ai_filters['website'])))
        
#         # [SMART TOPIC FILTER] (Root)
#         if ai_filters.get("topic"):
#             raw_topic = ai_filters['topic'].strip()
#             topic_variations = list(set([
#                 raw_topic,                  
#                 raw_topic.lower(),          
#                 raw_topic.capitalize(),     
#                 raw_topic.title(),          
#                 raw_topic.upper()           
#             ]))
#             logger.info(f"Topic filtering variations: {topic_variations}")
#             conditions.append(rest.FieldCondition(key="topic", match=rest.MatchAny(any=topic_variations)))
        
#         # [SENTIMENT FILTER] (Root)
#         if ai_filters.get("sentiment"):
#             val = ai_filters['sentiment']
#             if val == "positive": conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(gte=0.25)))
#             elif val == "negative": conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(lte=-0.25)))
        
#         # [DATE FILTER] (Root)
#         if ai_filters.get("days_ago") and isinstance(ai_filters["days_ago"], int):
#             cutoff_date = datetime.utcnow() - timedelta(days=ai_filters["days_ago"])
#             conditions.append(rest.FieldCondition(key="publish_date", range=rest.DatetimeRange(gte=cutoff_date.isoformat())))

#         return rest.Filter(must=conditions) if conditions else None

#     async def _search_qdrant(self, query: str, qdrant_filter: Optional[rest.Filter], limit: int = 5) -> List[rest.ScoredPoint]:
#         try:
#             logger.info(f"üîç Qdrant Search | Limit: {limit} | Filter: {qdrant_filter}")
#             embedding_result = genai.embed_content(
#                 model=self.embedding_model, content=query, task_type="retrieval_query", output_dimensionality=self.vector_size
#             )
            
#             results = self.qdrant_client.search(
#                 collection_name=self.qdrant_collection_name,
#                 query_vector=embedding_result['embedding'],
#                 query_filter=qdrant_filter,
#                 limit=limit
#             )
#             return results
#         except Exception as e:
#             logger.error(f"‚ùå Qdrant Search Error: {e}")
#             return []

#     async def _resolve_article_id(self, input_id: str) -> str:
#         if not input_id or len(input_id) != 24: return input_id
#         try:
#             doc = await self.articles_collection.find_one({"_id": ObjectId(input_id)}, {"article_id": 1})
#             return doc["article_id"] if doc else input_id
#         except: return input_id

#     async def handle_chat(self, request: ChatRequest) -> ChatResponse:
#         conversation_id = request.conversation_id or str(uuid.uuid4())
        
#         if request.context.current_page == "detail_page" and request.context.article_id:
#             request.context.article_id = await self._resolve_article_id(request.context.article_id)

#         history = await self._get_chat_history(request.user_id, conversation_id)
        
#         analysis = await self._analyze_query(request.query, history, request.context)
#         intent = analysis.get("intent", "general_search")
#         dependency = analysis.get("dependency", "main")
#         extracted_filters = analysis.get("filters", {})
        
#         requested_quantity = extracted_filters.get("quantity")
#         limit = requested_quantity if requested_quantity else 5
        
#         logger.info(f"Analysis -> Intent: {intent} | Quantity: {requested_quantity}")

#         search_query = request.query
#         context_query_append = ""
#         if dependency == "sub":
#             last_main_query = next((h.query for h in history if getattr(h, 'dependency', 'main') == 'main'), None)
#             if last_main_query:
#                 search_query = f"{last_main_query} {search_query}"
#                 context_query_append = f"(Ng·ªØ c·∫£nh c≈©: '{last_main_query}')"

#         base_filters = {}
#         strategy = "Global Search"
#         should_fallback_to_global = False

#         is_list_sort_context = (
#             request.context.current_page == "list_page" and 
#             request.context.search_id and 
#             request.context.sort_by and 
#             request.context.sort_by != "relevance"
#         )
        
#         # Ki·ªÉm tra c√≥ b·ªô l·ªçc n·ªôi dung c·ª• th·ªÉ kh√¥ng
#         has_content_filters = any(
#             extracted_filters.get(k) is not None
#             for k in ["topic", "website", "sentiment", "days_ago"]
#         )

#         # --- LOGIC CHI·∫æN L∆Ø·ª¢C T√åM KI·∫æM ---
        
#         # 1. Chi ti·∫øt b√†i vi·∫øt
#         if request.context.current_page == "detail_page" and request.context.article_id:
#              base_filters = {"article_id": request.context.article_id}
#              strategy = "Single Page Context"

#         # 2. Trang danh s√°ch (List Page)
#         elif request.context.current_page == "list_page" and request.context.search_id:
#             if has_content_filters:
#                 base_filters = {"search_id": request.context.search_id}
#                 strategy = "Scoped Search (With Filters)"
#                 should_fallback_to_global = True
#             elif is_list_sort_context:
#                 if intent == "contextual_summary" or (dependency == "sub" and intent == "specific_detail"):
#                     top_ids = await self._get_top_article_ids_from_mongo(
#                         request.context.search_id,
#                         request.context.sort_by,
#                         request.context.sort_order or "desc",
#                         limit
#                     )
#                     if top_ids:
#                         base_filters = {"article_id": top_ids}
#                         strategy = f"List Sort ({request.context.sort_by}) [Sub/Summary]"
#                         limit = len(top_ids) 
#                     else:
#                         base_filters = {"search_id": request.context.search_id}
#                         strategy = "Session Context (Fallback)"
#                 else:
#                     base_filters = {"search_id": request.context.search_id}
#                     strategy = "Session Context (Filtered)"
            
#             # --- UPDATE: T√°ch Logic Summary v√† Search ---
#             elif intent == "contextual_summary":
#                 # N·∫øu mu·ªën t√≥m t·∫Øt, ch·ªâ t√¨m trong list hi·ªán t·∫°i, KH√îNG fallback ra ngo√†i
#                 base_filters = {"search_id": request.context.search_id}
#                 strategy = "Session Context (Summary)"
            
#             elif intent == "general_search":
#                 # N·∫øu t√¨m ki·∫øm th√¥ng tin, ∆∞u ti√™n t√¨m trong list, nh∆∞ng cho ph√©p fallback ra to√†n DB
#                 base_filters = {"search_id": request.context.search_id}
#                 strategy = "Session Context (Search)"
#                 should_fallback_to_global = True 
        
#         # ƒê·∫£m b·∫£o lo·∫°i t√†i li·ªáu l√† ai_summary n·∫øu c·∫ßn t√≥m t·∫Øt
#         if intent == "contextual_summary":
#             base_filters["type"] = "ai_summary"
#         elif "type" not in base_filters:
#             base_filters["type"] = "ai_summary"

#         # --- TH·ª∞C HI·ªÜN T√åM KI·∫æM ---

#         # 1. INITIAL SEARCH
#         final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
#         results = await self._search_qdrant(search_query, final_filter, limit=limit)

#         # 2. FALLBACK 0: Scoped -> Global
#         if not results and should_fallback_to_global:
#             logger.info("‚ö†Ô∏è Scoped Search empty. Fallback to Global Search...")
#             if "search_id" in base_filters: 
#                 del base_filters["search_id"]
            
#             final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
#             results = await self._search_qdrant(search_query, final_filter, limit=limit)
            
#             if results:
#                 strategy = "Global Search (Fallback from Scoped)"

#         # 3. FALLBACK A: B·ªè type=ai_summary
#         if not results and base_filters.get("type") == "ai_summary":
#             logger.info("‚ö†Ô∏è No pre-computed summaries found. Fallback to full text search...")
#             if "type" in base_filters: 
#                 del base_filters["type"]
            
#             final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
#             results = await self._search_qdrant(search_query, final_filter, limit=limit)

#         # 4. FALLBACK B: B·ªè Topic/Content Filters (Ch·ªâ gi·ªØ Keyword)
#         if not results and has_content_filters:
#             logger.info("‚ö†Ô∏è Still no results. Relaxing strict content filters...")
#             relaxed_filters = extracted_filters.copy()
#             for key in ["topic", "website", "days_ago"]:
#                 if key in relaxed_filters:
#                     del relaxed_filters[key]
            
#             final_filter = self._build_qdrant_filters(base_filters, {"filters": relaxed_filters})
#             results = await self._search_qdrant(search_query, final_filter, limit=limit)
#             if results:
#                 strategy += " (Relaxed Filters)"

#         context_parts = []
#         sources = []
#         seen = set()

#         if not results:
#             if intent == "contextual_summary":
#                 final_answer = "Hi·ªán kh√¥ng t√¨m th·∫•y b√†i b√°o n√†o ph√π h·ª£p v·ªõi y√™u c·∫ßu ƒë·ªÉ t√≥m t·∫Øt."
#             else:
#                 final_answer = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong danh s√°ch n√†y."
#         else:
#             for pt in results:
#                 payload = pt.payload or {}
#                 content = payload.get("summary_text") if payload.get("type") == "ai_summary" else payload.get("text", "")
#                 content = "\n- ".join(content) if isinstance(content, list) else str(content)
                
#                 title = payload.get("title", "No Title")
#                 # L·∫•y ID t·ª´ root ho·∫∑c metadata
#                 aid = payload.get("article_id") or payload.get("metadata", {}).get("article_id", "unknown")
                
#                 # --- NEW: Extract Metadata for Prompt ---
#                 publish_date = payload.get("publish_date", "N/A")
                
#                 # ∆Øu ti√™n l·∫•y 'ai_sentiment_score', n·∫øu kh√¥ng c√≥ th√¨ l·∫•y 'sentiment'
#                 sentiment_score = payload.get("ai_sentiment_score", payload.get("sentiment", "N/A"))
                
#                 # ∆Øu ti√™n l·∫•y 'site_categories', n·∫øu kh√¥ng c√≥ th√¨ l·∫•y 'topic'
#                 site_categories = payload.get("site_categories", payload.get("topic", "N/A"))
                
#                 context_parts.append(
#                     f"--- B√†i: {title} ---\n"
#                     f"Ng√†y ƒëƒÉng: {publish_date}\n"
#                     f"Ch·ªâ s·ªë c·∫£m x√∫c: {sentiment_score}\n"
#                     f"Ch·ªß ƒë·ªÅ/Categories: {site_categories}\n"
#                     f"N·ªôi dung:\n{content}"
#                 )
                
#                 if title not in seen:
#                     sources.append(SourcedAnswer(article_id=str(aid), title=title))
#                     seen.add(title)

#             chat_history_str = chr(10).join([
#                 f"- User: {h.query}\n  Bot: {h.answer}" 
#                 for h in reversed(history[:2])
#             ])

#             prompt = (
#                 f"C√¢u h·ªèi ng∆∞·ªùi d√πng: {request.query} {context_query_append}\n"
#                 f"L·ªãch s·ª≠ h·ªôi tho·∫°i (ƒë·ªÉ tham kh·∫£o ng·ªØ c·∫£nh):\n"
#                 f"{chat_history_str}\n\n"
#                 f"D·ªØ li·ªáu t√¨m ƒë∆∞·ª£c ({strategy}):\n{chr(10).join(context_parts)}\n\n"
#                 f"Y√äU C·∫¶U: Tr·∫£ l·ªùi c√¢u h·ªèi tr√™n. N·∫øu d·ªØ li·ªáu l√† c√°c b√†i b√°o r·ªùi r·∫°c, h√£y t·ªïng h·ª£p ch√∫ng th√†nh m·ªôt b·∫£n t√≥m t·∫Øt m·∫°ch l·∫°c."
#             )
#             resp = await self.llm.generate_content_async(prompt)
#             final_answer = resp.text

#         await self._save_chat_history(request.user_id, conversation_id, request.query, final_answer, intent, dependency)
        
#         return ChatResponse(
#             answer=final_answer, conversation_id=conversation_id, sources=sources,
#             intent_detected=intent, dependency_label=dependency, strategy_used=strategy
#         )





# import logging
# import uuid
# import asyncio
# from datetime import datetime, timedelta
# from typing import List, Dict, Optional, Tuple, Any
# from collections import defaultdict
# import json
# import re

# import google.generativeai as genai
# from qdrant_client import QdrantClient
# from qdrant_client.http import models as rest
# from bson import ObjectId
# from pymongo import DESCENDING, ASCENDING

# from config import settings
# from database import get_mongo_db
# from models import ChatRequest, ChatResponse, ChatHistory, SourcedAnswer, ChatContext

# logger = logging.getLogger(__name__)

# # --- SYSTEM PROMPT ROUTER ---
# SYSTEM_PROMPT_ROUTER = """
# B·∫°n l√† AI Query Router. Nhi·ªám v·ª•: Ph√¢n t√≠ch ng·ªØ c·∫£nh v√† c√¢u h·ªèi ƒë·ªÉ ƒë·ªãnh tuy·∫øn.

# --- INPUT DATA ---
# 1. Context Page: "home_page" | "list_page" | "detail_page"
# 2. Query: C√¢u h·ªèi user.
# 3. Chat History: L·ªãch s·ª≠.

# --- PH√ÇN T√çCH ---
# 1. X√ÅC ƒê·ªäNH DEPENDENCY (S·ª± ph·ª• thu·ªôc):
#     - "main": C√¢u h·ªèi ƒê·ªòC L·∫¨P, ƒë·∫ßy ƒë·ªß ch·ªß ng·ªØ/v·ªã ng·ªØ ho·∫∑c m·ªü ra ch·ªß ƒë·ªÅ m·ªõi.
#     - "sub": C√¢u h·ªèi PH·ª§ THU·ªòC (Follow-up). D·∫•u hi·ªáu: 
#         + ƒê·∫°i t·ª´ thay th·∫ø ("n√≥", "√¥ng ·∫•y", "b√†i n√†y", "danh s√°ch ƒë√≥", ...).
#         + C√¢u h·ªèi ng·∫Øn/c·ª•t ("th·∫ø c√≤n t√°c gi·∫£?", "c√≤n ng√†y mai?", "t·∫°i sao?", ...).
#         + B·∫Øt ƒë·∫ßu b·∫±ng t·ª´ n·ªëi ("v·∫≠y th√¨", "n·∫øu th·∫ø", ...).

# 2. INTENT:
#     - "contextual_summary": T√≥m t·∫Øt, t·ªïng h·ª£p th√¥ng tin t·ª´ Context hi·ªán t·∫°i (List ho·∫∑c Detail).
#     - "specific_detail": H·ªèi chi ti·∫øt v·ªÅ 1 ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ.
#     - "general_search": T√¨m ki·∫øm m·ªü r·ªông, ki·∫øn th·ª©c chung.

# 3. TR√çCH XU·∫§T FILTERS & QUANTITY:
#     - website: "vneconomy.vn" | "vnexpress.net"
#     - days_ago: int (VD: "3 ng√†y qua" -> 3)
#     - topic: string (Ch·ªß ƒë·ªÅ b√†i b√°o. C·ªë g·∫Øng tr√≠ch xu·∫•t t√™n chuy√™n m·ª•c ch√≠nh x√°c n·∫øu c√≥ th·ªÉ).
#     - sentiment: "positive" | "negative"
#     - quantity: int (S·ªë l∆∞·ª£ng b√†i b√°o user mu·ªën x·ª≠ l√Ω. VD: "5 b√†i ƒë·∫ßu", "top 3" -> 5, 3. M·∫∑c ƒë·ªãnh null).

# --- LOGIC MATRIX ---
# | Page | Query keywords | -> Intent |
# | :--- | :--- | :--- |
# | **list_page** | T·ª´ kh√≥a s·ªë nhi·ªÅu ("c√°c b√†i", "danh s√°ch", "nh·ªØng tin n√†y") HO·∫∂C t·ª´ kh√≥a t√≥m t·∫Øt ("t·ªïng h·ª£p", "ƒëi·ªÉm tin") | -> **contextual_summary** |
# | **detail_page** | H·ªèi t√≥m t·∫Øt, n·ªôi dung ch√≠nh, ƒë·∫°i √Ω | -> **contextual_summary** |
# | **detail_page** | H·ªèi ai, c√°i g√¨, ·ªü ƒë√¢u, khi n√†o (c·ªßa b√†i b√°o n√†y) | -> **specific_detail** |
# | **home_page** | B·∫•t k·ª≥ c√¢u h·ªèi n√†o | -> **general_search** |

# OUTPUT JSON:
# {
#     "intent": "string",
#     "dependency": "string",
#     "filters": {
#         "website": "string | null",
#         "days_ago": "integer | null",
#         "topic": "string | null",
#         "sentiment": "string | null",
#         "quantity": "integer | null"
#     }
# }
# """

# SYSTEM_PROMPT_CHAT = (
#     "B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh. Tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin cung c·∫•p.\n"
#     "L∆ØU √ù QUAN TR·ªåNG:\n"
#     "- N·∫øu c√¢u h·ªèi l√† c√¢u ph·ª• (Sub-question) ho·∫∑c tham chi·∫øu s·ªë th·ª© t·ª± (v√≠ d·ª•: 'b√†i 1', 'tin ƒë·∫ßu ti√™n', 'ph·∫ßn 1'), h√£y CƒÇN C·ª® V√ÄO L·ªäCH S·ª¨ CHAT (c√¢u tr·∫£ l·ªùi tr∆∞·ªõc c·ªßa Bot) ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c b√†i b√°o ƒëang ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn.\n"
#     "- N·∫øu c√¢u h·ªèi l√† c√¢u ch√≠nh (main) tr·∫£ l·ªùi m√† kh√¥ng c·∫ßn d·ª±a v√†o l·ªãch s·ª≠ chat.\n"
#     "- Lu√¥n tr√≠ch d·∫´n ngu·ªìn (Source) cho m·ªçi th√¥ng tin ƒë∆∞a ra."
# )

# class ChatService:
#     def __init__(self):
#         try:
#             genai.configure(api_key=settings.google_api_key)
#             self.llm = genai.GenerativeModel('gemini-2.5-flash', system_instruction=SYSTEM_PROMPT_CHAT)
#             self.router_llm = genai.GenerativeModel('gemini-2.5-flash', generation_config={"response_mime_type": "application/json"})
#             self.embedding_model = 'models/text-embedding-004'
#             self.vector_size = 384
            
#             self.db = get_mongo_db()
#             self.chat_histories_collection = self.db['chat_histories']
#             self.articles_collection = self.db['articles'] 
            
#             self.qdrant_client = QdrantClient(url=settings.qdrant_url, api_key=settings.qdrant_api_key)
#             self.qdrant_collection_name = settings.qdrant_collection_name
#             logger.info(f"ChatService V13.5 Ready (Updated: Root Payload Structure for Filters).")
#         except Exception as e:
#             logger.error(f"Init Error: {e}")
#             raise

#     async def _get_chat_history(self, user_id: str, conversation_id: str) -> List[ChatHistory]:
#         cursor = self.chat_histories_collection.find({
#             "user_id": user_id, "conversation_id": conversation_id
#         }).sort("created_at", -1).limit(5)
#         history = await cursor.to_list(length=5)
#         return [ChatHistory(**h) for h in history]

#     async def _save_chat_history(self, user_id: str, conversation_id: str, query: str, answer: str, intent: str, dependency: str):
#         await self.chat_histories_collection.insert_one({
#             "user_id": user_id, "conversation_id": conversation_id,
#             "query": query, "answer": answer, 
#             "intent": intent, "dependency": dependency,
#             "created_at": datetime.utcnow()
#         })

#     async def _analyze_query(self, query: str, history: List[ChatHistory], context: ChatContext) -> Dict[str, Any]:
#         try:
#             chronological_history = list(reversed(history))
#             history_txt = "\n".join([f"User: {h.query}\nBot: {h.answer}" for h in chronological_history])
            
#             prompt = (
#                 f"{SYSTEM_PROMPT_ROUTER}\n\n"
#                 f"--- RUNTIME DATA ---\n"
#                 f"Context Page: {context.current_page}\n"
#                 f"Chat History:\n{history_txt}\n"
#                 f"Current Query: {query}\n"
#             )
#             response = await self.router_llm.generate_content_async(prompt)
#             return json.loads(response.text)
#         except Exception as e:
#             logger.error(f"Router Error: {e}")
#             return {"dependency": "main", "intent": "general_search", "filters": {}}

#     async def _get_top_article_ids_from_mongo(self, search_id: str, sort_by: str, sort_order: str, limit: int) -> List[str]:
#         """
#         Truy v·∫•n MongoDB ƒë·ªÉ l·∫•y danh s√°ch Article ID ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp ch√≠nh x√°c.
#         """
#         if not search_id:
#             return []
        
#         # Mapping sort key
#         sort_field = "publish_date"
#         if sort_by == "sentiment":
#             sort_field = "sentiment"
#         elif sort_by == "publish_date":
#             sort_field = "publish_date"
            
#         direction = DESCENDING if sort_order == "desc" else ASCENDING
        
#         logger.info(f"üîç Mongo Sort: search_id={search_id} | field={sort_field} | dir={direction} | limit={limit}")
        
#         cursor = self.articles_collection.find(
#             {"search_id": search_id},
#             {"article_id": 1}
#         ).sort(sort_field, direction).limit(limit)
        
#         docs = await cursor.to_list(length=limit)
#         return [doc["article_id"] for doc in docs if "article_id" in doc]

#     def _build_qdrant_filters(self, base_filters: dict, extracted_filters: dict) -> Optional[rest.Filter]:
#         conditions = []
        
#         # X·ª≠ l√Ω Base Filters (t·ª´ Context)
#         for key, value in base_filters.items():
#             if value:
#                 # T·∫•t c·∫£ c√°c key n√†y (article_id, search_id, type) gi·ªù ƒë·ªÅu n·∫±m ·ªü ROOT payload
#                 if key == "article_id":
#                     if isinstance(value, list):
#                         conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchAny(any=value)))
#                     else:
#                         conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchValue(value=value)))
#                 elif key == "search_id":
#                     conditions.append(rest.FieldCondition(key="search_id", match=rest.MatchValue(value=value)))
#                 else:
#                     # C√°c tr∆∞·ªùng kh√°c nh∆∞ 'type'
#                     conditions.append(rest.FieldCondition(key=key, match=rest.MatchValue(value=value)))

#         ai_filters = extracted_filters.get("filters", {})
        
#         # [UPDATE] Website Filter: D√πng key="website" (Root) thay v√¨ metadata.website
#         if ai_filters.get("website"):
#             conditions.append(rest.FieldCondition(key="website", match=rest.MatchValue(value=ai_filters['website'])))
        
#         # [SMART TOPIC FILTER] (Root)
#         if ai_filters.get("topic"):
#             raw_topic = ai_filters['topic'].strip()
#             topic_variations = list(set([
#                 raw_topic,                  
#                 raw_topic.lower(),          
#                 raw_topic.capitalize(),     
#                 raw_topic.title(),          
#                 raw_topic.upper()           
#             ]))
#             logger.info(f"Topic filtering variations: {topic_variations}")
#             conditions.append(rest.FieldCondition(key="topic", match=rest.MatchAny(any=topic_variations)))
        
#         # [SENTIMENT FILTER] (Root)
#         if ai_filters.get("sentiment"):
#             val = ai_filters['sentiment']
#             if val == "positive": conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(gte=0.25)))
#             elif val == "negative": conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(lte=-0.25)))
        
#         # [DATE FILTER] (Root)
#         if ai_filters.get("days_ago") and isinstance(ai_filters["days_ago"], int):
#             cutoff_date = datetime.utcnow() - timedelta(days=ai_filters["days_ago"])
#             conditions.append(rest.FieldCondition(key="publish_date", range=rest.DatetimeRange(gte=cutoff_date.isoformat())))

#         return rest.Filter(must=conditions) if conditions else None

#     async def _search_qdrant(self, query: str, qdrant_filter: Optional[rest.Filter], limit: int = 5) -> List[rest.ScoredPoint]:
#         try:
#             logger.info(f"üîç Qdrant Search | Limit: {limit} | Filter: {qdrant_filter}")
#             embedding_result = genai.embed_content(
#                 model=self.embedding_model, content=query, task_type="retrieval_query", output_dimensionality=self.vector_size
#             )
            
#             results = self.qdrant_client.search(
#                 collection_name=self.qdrant_collection_name,
#                 query_vector=embedding_result['embedding'],
#                 query_filter=qdrant_filter,
#                 limit=limit
#             )
#             return results
#         except Exception as e:
#             logger.error(f"‚ùå Qdrant Search Error: {e}")
#             return []

#     async def _resolve_article_id(self, input_id: str) -> str:
#         if not input_id or len(input_id) != 24: return input_id
#         try:
#             doc = await self.articles_collection.find_one({"_id": ObjectId(input_id)}, {"article_id": 1})
#             return doc["article_id"] if doc else input_id
#         except: return input_id

#     async def handle_chat(self, request: ChatRequest) -> ChatResponse:
#         conversation_id = request.conversation_id or str(uuid.uuid4())
        
#         if request.context.current_page == "detail_page" and request.context.article_id:
#             request.context.article_id = await self._resolve_article_id(request.context.article_id)

#         history = await self._get_chat_history(request.user_id, conversation_id)
        
#         analysis = await self._analyze_query(request.query, history, request.context)
#         intent = analysis.get("intent", "general_search")
#         dependency = analysis.get("dependency", "main")
#         extracted_filters = analysis.get("filters", {})
        
#         requested_quantity = extracted_filters.get("quantity")
#         limit = requested_quantity if requested_quantity else 5
        
#         logger.info(f"Analysis -> Intent: {intent} | Quantity: {requested_quantity}")

#         search_query = request.query
#         context_query_append = ""
#         if dependency == "sub":
#             last_main_query = next((h.query for h in history if getattr(h, 'dependency', 'main') == 'main'), None)
#             if last_main_query:
#                 search_query = f"{last_main_query} {search_query}"
#                 context_query_append = f"(Ng·ªØ c·∫£nh c≈©: '{last_main_query}')"

#         base_filters = {}
#         strategy = "Global Search"
#         should_fallback_to_global = False

#         is_list_sort_context = (
#             request.context.current_page == "list_page" and 
#             request.context.search_id and 
#             request.context.sort_by and 
#             request.context.sort_by != "relevance"
#         )
        
#         # Ki·ªÉm tra c√≥ b·ªô l·ªçc n·ªôi dung c·ª• th·ªÉ kh√¥ng
#         has_content_filters = any(
#             extracted_filters.get(k) is not None
#             for k in ["topic", "website", "sentiment", "days_ago"]
#         )

#         # --- LOGIC CHI·∫æN L∆Ø·ª¢C T√åM KI·∫æM ---
        
#         # 1. Chi ti·∫øt b√†i vi·∫øt
#         if request.context.current_page == "detail_page" and request.context.article_id:
#              base_filters = {"article_id": request.context.article_id}
#              strategy = "Single Page Context"

#         # 2. Trang danh s√°ch (List Page)
#         elif request.context.current_page == "list_page" and request.context.search_id:
#             if has_content_filters:
#                 base_filters = {"search_id": request.context.search_id}
#                 strategy = "Scoped Search (With Filters)"
#                 should_fallback_to_global = True
#             elif is_list_sort_context:
#                 if intent == "contextual_summary" or (dependency == "sub" and intent == "specific_detail"):
#                     top_ids = await self._get_top_article_ids_from_mongo(
#                         request.context.search_id,
#                         request.context.sort_by,
#                         request.context.sort_order or "desc",
#                         limit
#                     )
#                     if top_ids:
#                         base_filters = {"article_id": top_ids}
#                         strategy = f"List Sort ({request.context.sort_by}) [Sub/Summary]"
#                         limit = len(top_ids) 
#                     else:
#                         base_filters = {"search_id": request.context.search_id}
#                         strategy = "Session Context (Fallback)"
#                 else:
#                     base_filters = {"search_id": request.context.search_id}
#                     strategy = "Session Context (Filtered)"
#             elif intent == "contextual_summary" or intent == "general_search":
#                 base_filters = {"search_id": request.context.search_id}
#                 strategy = "Session Context (Relevance)"
        
#         # ƒê·∫£m b·∫£o lo·∫°i t√†i li·ªáu l√† ai_summary n·∫øu c·∫ßn t√≥m t·∫Øt
#         if intent == "contextual_summary":
#             base_filters["type"] = "ai_summary"
#         elif "type" not in base_filters:
#             base_filters["type"] = "ai_summary"

#         # --- TH·ª∞C HI·ªÜN T√åM KI·∫æM ---

#         # 1. INITIAL SEARCH
#         final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
#         results = await self._search_qdrant(search_query, final_filter, limit=limit)

#         # 2. FALLBACK 0: Scoped -> Global
#         if not results and should_fallback_to_global:
#             logger.info("‚ö†Ô∏è Scoped Search empty. Fallback to Global Search...")
#             if "search_id" in base_filters: 
#                 del base_filters["search_id"]
            
#             final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
#             results = await self._search_qdrant(search_query, final_filter, limit=limit)
            
#             if results:
#                 strategy = "Global Search (Fallback from Scoped)"

#         # 3. FALLBACK A: B·ªè type=ai_summary
#         if not results and base_filters.get("type") == "ai_summary":
#             logger.info("‚ö†Ô∏è No pre-computed summaries found. Fallback to full text search...")
#             if "type" in base_filters: 
#                 del base_filters["type"]
            
#             final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
#             results = await self._search_qdrant(search_query, final_filter, limit=limit)

#         # 4. FALLBACK B: B·ªè Topic/Content Filters (Ch·ªâ gi·ªØ Keyword)
#         if not results and has_content_filters:
#             logger.info("‚ö†Ô∏è Still no results. Relaxing strict content filters...")
#             relaxed_filters = extracted_filters.copy()
#             for key in ["topic", "website", "days_ago"]:
#                 if key in relaxed_filters:
#                     del relaxed_filters[key]
            
#             final_filter = self._build_qdrant_filters(base_filters, {"filters": relaxed_filters})
#             results = await self._search_qdrant(search_query, final_filter, limit=limit)
#             if results:
#                 strategy += " (Relaxed Filters)"

#         context_parts = []
#         sources = []
#         seen = set()

#         if not results:
#             if intent == "contextual_summary":
#                 final_answer = "Hi·ªán kh√¥ng t√¨m th·∫•y b√†i b√°o n√†o ph√π h·ª£p v·ªõi y√™u c·∫ßu ƒë·ªÉ t√≥m t·∫Øt."
#             else:
#                 final_answer = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong danh s√°ch n√†y."
#         else:
#             for pt in results:
#                 payload = pt.payload or {}
#                 content = payload.get("summary_text") if payload.get("type") == "ai_summary" else payload.get("text", "")
#                 content = "\n- ".join(content) if isinstance(content, list) else str(content)
                
#                 title = payload.get("title", "No Title")
#                 # L·∫•y ID t·ª´ root ho·∫∑c metadata
#                 aid = payload.get("article_id") or payload.get("metadata", {}).get("article_id", "unknown")
                
#                 context_parts.append(f"--- B√†i: {title} ---\n{content}")
#                 if title not in seen:
#                     sources.append(SourcedAnswer(article_id=str(aid), title=title))
#                     seen.add(title)

#             chat_history_str = chr(10).join([
#                 f"- User: {h.query}\n  Bot: {h.answer}" 
#                 for h in reversed(history[:2])
#             ])

#             prompt = (
#                 f"C√¢u h·ªèi ng∆∞·ªùi d√πng: {request.query} {context_query_append}\n"
#                 f"L·ªãch s·ª≠ h·ªôi tho·∫°i (ƒë·ªÉ tham kh·∫£o ng·ªØ c·∫£nh):\n"
#                 f"{chat_history_str}\n\n"
#                 f"D·ªØ li·ªáu t√¨m ƒë∆∞·ª£c ({strategy}):\n{chr(10).join(context_parts)}\n\n"
#                 f"Y√äU C·∫¶U: Tr·∫£ l·ªùi c√¢u h·ªèi tr√™n. N·∫øu d·ªØ li·ªáu l√† c√°c b√†i b√°o r·ªùi r·∫°c, h√£y t·ªïng h·ª£p ch√∫ng th√†nh m·ªôt b·∫£n t√≥m t·∫Øt m·∫°ch l·∫°c."
#             )
#             resp = await self.llm.generate_content_async(prompt)
#             final_answer = resp.text

#         await self._save_chat_history(request.user_id, conversation_id, request.query, final_answer, intent, dependency)
        
#         return ChatResponse(
#             answer=final_answer, conversation_id=conversation_id, sources=sources,
#             intent_detected=intent, dependency_label=dependency, strategy_used=strategy
#         )