import logging
import uuid
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Any
from collections import defaultdict
import json
import re

import google.generativeai as genai
from qdrant_client import QdrantClient
from qdrant_client.http import models as rest
from bson import ObjectId
from pymongo import DESCENDING, ASCENDING

from config import settings
from database import get_mongo_db
from models import ChatRequest, ChatResponse, ChatHistory, SourcedAnswer, ChatContext

logger = logging.getLogger(__name__)

# --- SYSTEM PROMPT ROUTER ---
SYSTEM_PROMPT_ROUTER = """
B·∫°n l√† AI Query Router. Nhi·ªám v·ª•: Ph√¢n t√≠ch ng·ªØ c·∫£nh v√† c√¢u h·ªèi ƒë·ªÉ ƒë·ªãnh tuy·∫øn.

--- INPUT DATA ---
1. Context Page: "home_page" | "list_page" | "detail_page" | "my_page"
2. Query: C√¢u h·ªèi user.
3. Chat History: L·ªãch s·ª≠.

--- PH√ÇN T√çCH ---
1. X√ÅC ƒê·ªäNH DEPENDENCY (S·ª± ph·ª• thu·ªôc):
    - "main": C√¢u h·ªèi ƒê·ªòC L·∫¨P, ƒë·∫ßy ƒë·ªß ch·ªß ng·ªØ/v·ªã ng·ªØ ho·∫∑c m·ªü ra ch·ªß ƒë·ªÅ m·ªõi.
    - "sub": C√¢u h·ªèi PH·ª§ THU·ªòC (Follow-up). D·∫•u hi·ªáu: 
        + ƒê·∫°i t·ª´ thay th·∫ø ("n√≥", "√¥ng ·∫•y", "b√†i n√†y", "danh s√°ch ƒë√≥", ...).
        + C√¢u h·ªèi ng·∫Øn/c·ª•t ("th·∫ø c√≤n t√°c gi·∫£?", "c√≤n ng√†y mai?", "t·∫°i sao?", ...).
        + B·∫Øt ƒë·∫ßu b·∫±ng t·ª´ n·ªëi ("v·∫≠y th√¨", "n·∫øu th·∫ø", ...).
        + Tham chi·∫øu th·ª© t·ª± ("b√†i 1", "c√°i th·ª© 2", "ph·∫ßn ƒë·∫ßu"...).
        + Tham chi·∫øu n·ªôi dung ("b√†i v·ªÅ gi√° v√†ng", "tin l·∫°m ph√°t"...).

2. INTENT:
    - "contextual_summary": T√≥m t·∫Øt, t·ªïng h·ª£p th√¥ng tin t·ª´ Context hi·ªán t·∫°i.
    - "specific_detail": H·ªèi chi ti·∫øt v·ªÅ 1 ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ.
    - "general_search": T√¨m ki·∫øm m·ªü r·ªông, ki·∫øn th·ª©c chung.

3. TR√çCH XU·∫§T FILTERS & QUANTITY:
    - website: "vneconomy.vn" | "vnexpress.net"
    - days_ago: int (VD: "3 ng√†y qua" -> 3)
    - topic: string (Ch·ªß ƒë·ªÅ b√†i b√°o).
    - sentiment: "positive" | "negative" | "neutral"
    - quantity: int (S·ªë l∆∞·ª£ng b√†i b√°o user mu·ªën x·ª≠ l√Ω. VD: "5 b√†i ƒë·∫ßu", "top 3" -> 5, 3. M·∫∑c ƒë·ªãnh null).

--- LOGIC MATRIX ---
| Page | Query keywords | -> Intent |
| :--- | :--- | :--- |
| **list_page** | T·ª´ kh√≥a s·ªë nhi·ªÅu ("c√°c b√†i", "danh s√°ch", "nh·ªØng tin n√†y") HO·∫∂C t·ª´ kh√≥a t√≥m t·∫Øt ("t·ªïng h·ª£p", "ƒëi·ªÉm tin") | -> **contextual_summary** |
| **my_page** | T·ª´ kh√≥a s·ªü h·ªØu/t·ªïng h·ª£p ("b√†i c·ªßa t√¥i", "t√†i li·ªáu v·ª´a up", "t√≥m t·∫Øt") | -> **contextual_summary** |
| **my_page** | H·ªèi chi ti·∫øt trong t√†i li·ªáu ƒë√£ up | -> **specific_detail** |
| **detail_page** | H·ªèi t√≥m t·∫Øt, n·ªôi dung ch√≠nh, ƒë·∫°i √Ω | -> **contextual_summary** |
| **detail_page** | H·ªèi ai, c√°i g√¨, ·ªü ƒë√¢u, khi n√†o (c·ªßa b√†i b√°o n√†y) | -> **specific_detail** |
| **home_page** | B·∫•t k·ª≥ c√¢u h·ªèi n√†o | -> **general_search** |

OUTPUT JSON:
{
    "intent": "string",
    "dependency": "string",
    "filters": {
        "website": "string | null",
        "days_ago": "integer | null",
        "topic": "string | null",
        "sentiment": "string | null",
        "quantity": "integer | null"
    }
}
"""

SYSTEM_PROMPT_CHAT = (
    "B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh. Tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin cung c·∫•p.\n"
    "L∆ØU √ù QUAN TR·ªåNG:\n"
    "- N·∫øu c√¢u h·ªèi l√† c√¢u ph·ª• (Sub-question) ho·∫∑c tham chi·∫øu s·ªë th·ª© t·ª± (v√≠ d·ª•: 'b√†i 1', 'tin ƒë·∫ßu ti√™n', 'ph·∫ßn 1'), h√£y CƒÇN C·ª® V√ÄO L·ªäCH S·ª¨ CHAT (c√¢u tr·∫£ l·ªùi tr∆∞·ªõc c·ªßa Bot) ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c b√†i b√°o ƒëang ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn.\n"
    "- Lu√¥n tr√≠ch d·∫´n ngu·ªìn (Source) cho m·ªçi th√¥ng tin ƒë∆∞a ra, m·ªói b√†i b√°o ch·ªâ tr√≠ch d·∫´n ngu·ªìn 1 l·∫ßn duy nh·∫•t."
)

class ChatService:
    def __init__(self):
        try:
            genai.configure(api_key=settings.google_api_key)
            self.llm = genai.GenerativeModel('gemini-2.5-flash', system_instruction=SYSTEM_PROMPT_CHAT)
            self.router_llm = genai.GenerativeModel('gemini-2.5-flash', generation_config={"response_mime_type": "application/json"})
            self.embedding_model = 'models/text-embedding-004'
            self.vector_size = 384
            
            self.db = get_mongo_db()
            self.chat_histories_collection = self.db['chat_histories']
            self.articles_collection = self.db['articles'] 
            
            self.qdrant_client = QdrantClient(url=settings.qdrant_url, api_key=settings.qdrant_api_key)
            self.qdrant_collection_name = settings.qdrant_collection_name
            logger.info(f"ChatService V18.0 Ready (Updated: Fix Quantity Logic & Prompt Injection).")
        except Exception as e:
            logger.error(f"Init Error: {e}")
            raise

    async def _get_chat_history(self, user_id: str, conversation_id: str) -> List[ChatHistory]:
        cursor = self.chat_histories_collection.find({
            "user_id": user_id, "conversation_id": conversation_id
        }).sort("created_at", -1).limit(5)
        history = await cursor.to_list(length=5)
        return [ChatHistory(**h) for h in history]

    async def _save_chat_history(self, user_id: str, conversation_id: str, query: str, answer: str, intent: str, dependency: str, sources: List[SourcedAnswer]):
        await self.chat_histories_collection.insert_one({
            "user_id": user_id, "conversation_id": conversation_id,
            "query": query, "answer": answer, 
            "intent": intent, "dependency": dependency,
            "sources": [s.dict() for s in sources],
            "created_at": datetime.utcnow()
        })

    async def _analyze_query(self, query: str, history: List[ChatHistory], context: ChatContext) -> Dict[str, Any]:
        try:
            chronological_history = list(reversed(history))
            history_txt = "\n".join([f"User: {h.query}\nBot: {h.answer}" for h in chronological_history])
            
            prompt = (
                f"{SYSTEM_PROMPT_ROUTER}\n\n"
                f"--- RUNTIME DATA ---\n"
                f"Context Page: {context.current_page}\n"
                f"Chat History:\n{history_txt}\n"
                f"Current Query: {query}\n"
            )
            response = await self.router_llm.generate_content_async(prompt)
            return json.loads(response.text)
        except Exception as e:
            logger.error(f"Router Error: {e}")
            return {"dependency": "main", "intent": "general_search", "filters": {}}

    async def _get_top_article_ids_from_mongo(self, search_id: str, sort_by: str, sort_order: str, limit: int) -> List[str]:
        if not search_id:
            return []
        
        sort_field = "publish_date"
        if sort_by == "sentiment":
            sort_field = "sentiment" 
        elif sort_by == "publish_date":
            sort_field = "publish_date"
            
        direction = DESCENDING if sort_order == "desc" else ASCENDING
        
        logger.info(f"üîç Mongo Sort: search_id={search_id} | field={sort_field} | dir={direction} | limit={limit}")
        
        cursor = self.articles_collection.find(
            {"search_id": search_id},
            {"article_id": 1}
        ).sort(sort_field, direction).limit(limit)
        
        docs = await cursor.to_list(length=limit)
        return [doc["article_id"] for doc in docs if "article_id" in doc]

    def _build_qdrant_filters(self, base_filters: dict, extracted_filters: dict) -> Optional[rest.Filter]:
        conditions = []
        
        for key, value in base_filters.items():
            if value:
                if key == "article_id":
                    if isinstance(value, list):
                        conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchAny(any=value)))
                    else:
                        conditions.append(rest.FieldCondition(key="article_id", match=rest.MatchValue(value=value)))
                elif key == "search_id":
                    conditions.append(rest.FieldCondition(key="search_id", match=rest.MatchValue(value=value)))
                elif key == "update_id":
                    conditions.append(rest.FieldCondition(key="update_id", match=rest.MatchValue(value=value)))
                else:
                    conditions.append(rest.FieldCondition(key=key, match=rest.MatchValue(value=value)))

        ai_filters = extracted_filters.get("filters", {})
        
        if ai_filters.get("website"):
            conditions.append(rest.FieldCondition(key="website", match=rest.MatchValue(value=ai_filters['website'])))
        
        if ai_filters.get("topic"):
            raw_topic = ai_filters['topic'].strip()
            topic_variations = list(set([
                raw_topic, raw_topic.lower(), raw_topic.capitalize(), raw_topic.title(), raw_topic.upper()
            ]))
            conditions.append(rest.FieldCondition(key="topic", match=rest.MatchAny(any=topic_variations)))
        
        if ai_filters.get("sentiment"):
            val = ai_filters['sentiment']
            sentiment_map = {
                "positive": "T√≠ch c·ª±c",
                "negative": "Ti√™u c·ª±c",
                "neutral": "Trung t√≠nh"
            }
            mapped_label = sentiment_map.get(val)
            if mapped_label:
                conditions.append(rest.FieldCondition(key="ai_sentiment_label", match=rest.MatchValue(value=mapped_label)))
            else:
                if val == "positive": 
                    conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(gte=0.25)))
                elif val == "negative": 
                    conditions.append(rest.FieldCondition(key="sentiment", range=rest.Range(lte=-0.25)))
        
        if ai_filters.get("days_ago") and isinstance(ai_filters["days_ago"], int):
            cutoff_date = datetime.utcnow() - timedelta(days=ai_filters["days_ago"])
            conditions.append(rest.FieldCondition(key="publish_date", range=rest.DatetimeRange(gte=cutoff_date.isoformat())))

        return rest.Filter(must=conditions) if conditions else None

    async def _search_qdrant(self, query: str, qdrant_filter: Optional[rest.Filter], limit: int = 5) -> List[rest.ScoredPoint]:
        try:
            logger.info(f"üîç Qdrant Search | Limit: {limit} | Filter: {qdrant_filter}")
            embedding_result = genai.embed_content(
                model=self.embedding_model, content=query, task_type="retrieval_query", output_dimensionality=self.vector_size
            )
            
            results = self.qdrant_client.search(
                collection_name=self.qdrant_collection_name,
                query_vector=embedding_result['embedding'],
                query_filter=qdrant_filter,
                limit=limit
            )
            return results
        except Exception as e:
            logger.error(f"‚ùå Qdrant Search Error: {e}")
            return []

    async def _resolve_article_id(self, input_id: str) -> str:
        if not input_id or len(input_id) != 24: return input_id
        try:
            doc = await self.articles_collection.find_one({"_id": ObjectId(input_id)}, {"article_id": 1})
            return doc["article_id"] if doc else input_id
        except: return input_id
    
    def _smart_resolve_article(self, query: str, sources: List[SourcedAnswer]) -> Optional[Tuple[str, str]]:
        if not sources:
            return None

        # 1. Check Ordinal 
        match = re.search(r'(?:b√†i|tin|ph·∫ßn|s·ªë|m·ª•c)\s+(?:th·ª©\s+)?(\d+)', query.lower())
        if match:
            try:
                val = int(match.group(1))
                idx = val - 1 if val > 0 else 0
                if 0 <= idx < len(sources):
                    logger.info(f"üîó Detected Ordinal Ref: Index {idx} -> {sources[idx].title}")
                    return sources[idx].article_id, sources[idx].title
            except:
                pass
        
        # Check text ordinal
        lower_q = query.lower()
        if "ƒë·∫ßu ti√™n" in lower_q or "th·ª© nh·∫•t" in lower_q: return sources[0].article_id, sources[0].title
        if ("th·ª© hai" in lower_q or "th·ª© 2" in lower_q) and len(sources) > 1: return sources[1].article_id, sources[1].title
        
        # 2. Check Semantic Keyword Matching
        best_match = None
        max_score = 0
        query_tokens = set(lower_q.split())
        
        for src in sources:
            title_tokens = set(src.title.lower().split())
            intersection = query_tokens.intersection(title_tokens)
            score = len(intersection)
            
            valid_match = False
            if score >= 2:
                valid_match = True
            elif score == 1:
                matched_word = list(intersection)[0]
                if len(matched_word) > 4: 
                    valid_match = True
            
            if valid_match and score > max_score:
                max_score = score
                best_match = src
        
        if best_match:
            return best_match.article_id, best_match.title

        return None

    async def handle_chat(self, request: ChatRequest) -> ChatResponse:
        conversation_id = request.conversation_id or str(uuid.uuid4())
        
        if request.context.current_page == "detail_page" and request.context.article_id:
            request.context.article_id = await self._resolve_article_id(request.context.article_id)

        history = await self._get_chat_history(request.user_id, conversation_id)
        
        analysis = await self._analyze_query(request.query, history, request.context)
        intent = analysis.get("intent", "general_search")
        dependency = analysis.get("dependency", "main")
        extracted_filters = analysis.get("filters", {})
        
        requested_quantity = extracted_filters.get("quantity")
        limit = requested_quantity if requested_quantity else 5
        
        logger.info(f"Analysis -> Intent: {intent} | Quantity: {requested_quantity}")

        search_query = request.query
        context_query_append = ""
        
        target_article_id = None
        target_article_title = None

        # [FIX 1] Logic Smart Reference ch·ªâ ch·∫°y khi kh√¥ng ph·∫£i y√™u c·∫ßu s·ªë l∆∞·ª£ng nhi·ªÅu
        # N·∫øu user h·ªèi "3 b√†i", ta c·∫ßn list, kh√¥ng ph·∫£i 1 b√†i c·ª• th·ªÉ.
        is_plural_request = requested_quantity and requested_quantity > 1

        if dependency == "sub" and not is_plural_request:
            last_bot_sources = history[0].sources if history else []
            resolved = self._smart_resolve_article(search_query, last_bot_sources)
            
            if resolved:
                target_article_id, target_article_title = resolved
                context_query_append = f"(Ng∆∞·ªùi d√πng ƒëang h·ªèi v·ªÅ b√†i: '{target_article_title}')"
            
            last_main_query = next((h.query for h in history if getattr(h, 'dependency', 'main') == 'main'), None)
            if last_main_query:
                search_query = f"{last_main_query} {search_query}"
                if not context_query_append:
                    context_query_append = f"(Ng·ªØ c·∫£nh c≈©: '{last_main_query}')"

        base_filters = {}
        strategy = "Global Search"
        should_fallback_to_global = False

        is_list_sort_context = (
            request.context.current_page == "list_page" and 
            request.context.search_id and 
            request.context.sort_by and 
            request.context.sort_by != "relevance"
        )
        
        has_content_filters = any(
            extracted_filters.get(k) is not None
            for k in ["topic", "website", "sentiment", "days_ago"]
        )

        top_sorted_ids = []

        # --- LOGIC CHI·∫æN L∆Ø·ª¢C T√åM KI·∫æM ---
        if target_article_id:
             base_filters = {"article_id": target_article_id}
             base_filters["type"] = "chunk" 
             strategy = f"Smart Reference (Target: {target_article_title})"
             
             if "topic" in extracted_filters: 
                 del extracted_filters["topic"]
             if "website" in extracted_filters: del extracted_filters["website"]
             if "days_ago" in extracted_filters: del extracted_filters["days_ago"]
        
        elif request.context.current_page == "detail_page" and request.context.article_id:
             base_filters = {"article_id": request.context.article_id}
             strategy = "Single Page Context"

        elif request.context.current_page == "list_page" and request.context.search_id:
            if has_content_filters:
                base_filters = {"search_id": request.context.search_id}
                strategy = "Scoped Search (With Filters)"
                should_fallback_to_global = True
            elif is_list_sort_context:
                if intent == "contextual_summary" or (dependency == "sub" and intent == "specific_detail"):
                    top_sorted_ids = await self._get_top_article_ids_from_mongo(
                        request.context.search_id,
                        request.context.sort_by,
                        request.context.sort_order or "desc",
                        limit
                    )
                    if top_sorted_ids:
                        base_filters = {"article_id": top_sorted_ids}
                        strategy = f"List Sort ({request.context.sort_by}) [Sub/Summary]"
                        limit = len(top_sorted_ids) 
                    else:
                        base_filters = {"search_id": request.context.search_id}
                        strategy = "Session Context (Fallback)"
                else:
                    base_filters = {"search_id": request.context.search_id}
                    strategy = "Session Context (Filtered)"
            elif intent == "contextual_summary":
                base_filters = {"search_id": request.context.search_id}
                strategy = "Session Context (Summary)"
            elif intent == "general_search" or intent == "specific_detail":
                base_filters = {"search_id": request.context.search_id}
                strategy = "Session Context (Search)"
                should_fallback_to_global = True 
        
        elif request.context.current_page == "my_page":
            base_filters["type"] = "my-page"
            strategy = "My Page Search"
            if request.context.update_id:
                base_filters["update_id"] = request.context.update_id
                strategy = f"My Page (UpdateID: {request.context.update_id})"
            else:
                strategy = "My Page (All User Uploads)"
                
        if target_article_id:
            pass 
        elif intent == "contextual_summary" and request.context.current_page != "my_page":
            base_filters["type"] = "ai_summary"
        elif "type" not in base_filters:
            if request.context.current_page != "my_page":
                base_filters["type"] = "chunk"

        # --- TH·ª∞C HI·ªÜN T√åM KI·∫æM ---
        final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
        results = await self._search_qdrant(search_query, final_filter, limit=limit)

        if not results and should_fallback_to_global:
            logger.info("‚ö†Ô∏è Scoped Search empty. Fallback to Global Search...")
            if "search_id" in base_filters: del base_filters["search_id"]
            if base_filters.get("type") == "chunk": pass 
            
            final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
            results = await self._search_qdrant(search_query, final_filter, limit=limit)
            if results: strategy = "Global Search (Fallback from Scoped)"

        if not results and base_filters.get("type") == "ai_summary":
            logger.info("‚ö†Ô∏è No pre-computed summaries found. Fallback to full text search...")
            if "type" in base_filters: 
                del base_filters["type"]
                if request.context.current_page == "my_page": base_filters["type"] = "my-page"
            
            final_filter = self._build_qdrant_filters(base_filters, {"filters": extracted_filters})
            results = await self._search_qdrant(search_query, final_filter, limit=limit)

        # --- RE-SORT RESULTS ---
        if results:
             def get_id(point):
                 return point.payload.get("article_id") or point.payload.get("metadata", {}).get("article_id")
             
             if top_sorted_ids:
                 id_map = {str(aid): i for i, aid in enumerate(top_sorted_ids)}
                 results.sort(key=lambda x: id_map.get(str(get_id(x)), 999))
                 logger.info("‚úÖ Re-sorted results match Mongo ID list (Sync Sources).")
             elif intent == "contextual_summary" and not target_article_id:
                 results.sort(key=lambda x: x.payload.get("publish_date", ""), reverse=True)
                 logger.info("‚úÖ Re-sorted results by Date Desc for Summary (Sync Sources).")

        context_parts = []
        sources = []
        seen = set()

        if not results:
            if intent == "contextual_summary":
                final_answer = "Hi·ªán kh√¥ng t√¨m th·∫•y n·ªôi dung ph√π h·ª£p ƒë·ªÉ t√≥m t·∫Øt."
            else:
                final_answer = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong danh s√°ch n√†y."
        else:
            for pt in results:
                payload = pt.payload or {}
                
                content = payload.get("summary_text") if payload.get("type") == "ai_summary" else payload.get("text", "")
                content = "\n- ".join(content) if isinstance(content, list) else str(content)
                
                title = payload.get("title", "No Title")
                aid = payload.get("article_id") or payload.get("metadata", {}).get("article_id", "unknown")
                
                publish_date = payload.get("publish_date", "N/A")
                site_categories = payload.get("site_categories", payload.get("topic", "N/A"))
                
                sentiment_label = payload.get("ai_sentiment_label", "N/A")
                sentiment_confidence = payload.get("ai_sentiment_score", "N/A")
                
                if sentiment_label == "N/A" and "sentiment" in payload:
                    sentiment_confidence = payload["sentiment"] 
                    sentiment_label = "Positive" if sentiment_confidence > 0 else "Negative"
                
                context_parts.append(
                    f"--- B√†i: {title} ---\n"
                    f"Ng√†y ƒëƒÉng: {publish_date}\n"
                    f"C·∫£m x√∫c AI: {sentiment_label} (ƒê·ªô tin c·∫≠y: {sentiment_confidence})\n"
                    f"Ch·ªß ƒë·ªÅ: {site_categories}\n"
                    f"N·ªôi dung:\n{content}"
                )
                
                if title not in seen:
                    sources.append(SourcedAnswer(article_id=str(aid), title=title))
                    seen.add(title)

            chat_history_str = chr(10).join([
                f"- User: {h.query}\n  Bot: {h.answer}" 
                for h in reversed(history[:2])
            ])

            # [FIX 2] Prompt Engineering: Inject Dependency & Force Data Priority
            prompt_instruction = ""
            if dependency == "main":
                prompt_instruction = (
                    "CH√ö √ù: ƒê√¢y l√† c√¢u h·ªèi ch√≠nh (Main Question). "
                    "H√£y ∆∞u ti√™n s·ª≠ d·ª•ng d·ªØ li·ªáu trong ph·∫ßn 'D·ªØ li·ªáu t√¨m ƒë∆∞·ª£c' b√™n d∆∞·ªõi ƒë·ªÉ tr·∫£ l·ªùi. "
                    "Ch·ªâ tham kh·∫£o l·ªãch s·ª≠ chat n·∫øu c·∫ßn bi·∫øt phong c√°ch tr·∫£ l·ªùi, KH√îNG d√πng d·ªØ li·ªáu c≈© n·∫øu n√≥ kh√¥ng li√™n quan."
                )
            else:
                prompt_instruction = "L∆∞u √Ω: ƒê√¢y l√† c√¢u h·ªèi ph·ª• (Sub-question), h√£y k·∫øt h·ª£p ng·ªØ c·∫£nh l·ªãch s·ª≠ chat ƒë·ªÉ tr·∫£ l·ªùi m·∫°ch l·∫°c."

            prompt = (
                f"C√¢u h·ªèi ng∆∞·ªùi d√πng: {request.query} {context_query_append}\n"
                f"Lo·∫°i c√¢u h·ªèi: {dependency.upper()}\n"
                f"{prompt_instruction}\n\n"
                f"L·ªãch s·ª≠ h·ªôi tho·∫°i (ƒë·ªÉ tham kh·∫£o ng·ªØ c·∫£nh):\n"
                f"{chat_history_str}\n\n"
                f"D·ªØ li·ªáu t√¨m ƒë∆∞·ª£c ({strategy}):\n{chr(10).join(context_parts)}\n\n"
                f"Y√äU C·∫¶U: Tr·∫£ l·ªùi c√¢u h·ªèi tr√™n d·ª±a tr√™n d·ªØ li·ªáu cung c·∫•p. Tr√≠ch d·∫´n ngu·ªìn r√µ r√†ng."
            )
            resp = await self.llm.generate_content_async(prompt)
            final_answer = resp.text

        await self._save_chat_history(request.user_id, conversation_id, request.query, final_answer, intent, dependency, sources)
        
        return ChatResponse(
            answer=final_answer, conversation_id=conversation_id, sources=sources,
            intent_detected=intent, dependency_label=dependency, strategy_used=strategy
        )